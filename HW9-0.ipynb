{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание\n",
    "\n",
    "Нужно реализовать rest api на базе flask (пример https://github.com/fimochka-sudo/GB_docker_flask_example)\n",
    "\n",
    "По шагам:\n",
    "0. выбрать себе датасет (который интересен или нравится больше всего), сделать pipeline (преобразования + модель), сохранить его на диск. Если не хочется пайплайн, то можно без него, но так вам же будет удобнее потом вызывать его из кода сервиса.\n",
    "1. установить удобную для себя среду разработки (pycharm прекрасен - https://www.jetbrains.com/pycharm/)\n",
    "2. для вашего проекта вам понадобится requirements.txt с пакетами. Можно за основу взять такой файл из проекта выше. Для его установки прям в pycharm можно открыть терминал и сделать pip install -r requirements.txt (находясь в корне проекта конечно же при этом)\n",
    "3. завести себе аккаунт на github (если его еще нет). У самого github есть такой \"hello world\" по работе с ним - https://guides.github.com/activities/hello-world/\n",
    "4. итоговый проект должен содержать: 1) каталог app/models/ (здесь модель-пайплайн предобученная) 2) файл app/run_server.py (здесь основной код flask-приложения) 3) requirements.txt (список пакетов, которые у вас используются в проекте - в корне проекта) 4) README.md (здесь какое-то описание, что вы делаете, что за данные, как запускать и т.д) 5) Dockerfile 6) docker-entrypoint.sh\n",
    "5. (<b>Опционально</b>): front-end сервис какой-то, который умеет принимать от пользователя введеные данные и ходить в ваш api. На самом деле полезно больше вам, т.к если ваш проект будет далее развиваться (новые модели, интересные подходы), то это хороший пунктик к резюме и в принципе - строчка в портфолио)\n",
    "\n",
    "Полезные ссылки:\n",
    "1. датасеты (для полета мысли): https://www.kaggle.com/datasets\n",
    "2. конкурс Сбербанка по недвижимости (можно этот набор данных также взять и обучить модель предсказывать стоимость жилья - неплохой такой сервис может получиться) - https://www.kaggle.com/c/sberbank-russian-housing-market/data Там же и ноутбуки с разными подходами есть.\n",
    "3. минималистичный пример связки keras/flask https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html для определения класса картинки\n",
    "4. неплохой такой пример (помимо того, что разобрали на занятии) связки docker/flask - https://cloud.croc.ru/blog/byt-v-teme/flask-prilozheniya-v-docker/\n",
    "5. https://www.digitalocean.com/community/tutorials/how-to-build-and-deploy-a-flask-application-using-docker-on-ubuntu-18-04\n",
    "\n",
    "p.s. если проблемы с выбором датасета, то пишите пожалуйста - будем вместе думать)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Создаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>AI.csv</th>\n",
       "      <th>wsbp.csv</th>\n",
       "      <th>wsrh.csv</th>\n",
       "      <th>wsth.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/30/2021 19:02:15</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1005.968994</td>\n",
       "      <td>82.079987</td>\n",
       "      <td>-13.818200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/30/2021 20:02:15</td>\n",
       "      <td>33.223209</td>\n",
       "      <td>1006.039978</td>\n",
       "      <td>80.348824</td>\n",
       "      <td>-14.015130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/30/2021 21:02:15</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1006.090027</td>\n",
       "      <td>80.495888</td>\n",
       "      <td>-13.943720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/30/2021 22:02:15</td>\n",
       "      <td>34.903080</td>\n",
       "      <td>1006.140015</td>\n",
       "      <td>81.833351</td>\n",
       "      <td>-14.217760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/30/2021 23:02:15</td>\n",
       "      <td>34.484661</td>\n",
       "      <td>1006.190002</td>\n",
       "      <td>79.476692</td>\n",
       "      <td>-15.350870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>1/31/2022 15:02:15</td>\n",
       "      <td>43.375000</td>\n",
       "      <td>992.799988</td>\n",
       "      <td>86.986160</td>\n",
       "      <td>-7.212864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>1/31/2022 16:02:15</td>\n",
       "      <td>41.029411</td>\n",
       "      <td>992.880371</td>\n",
       "      <td>79.485641</td>\n",
       "      <td>-7.497532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>1/31/2022 17:02:15</td>\n",
       "      <td>41.365849</td>\n",
       "      <td>993.257019</td>\n",
       "      <td>78.728760</td>\n",
       "      <td>-7.782199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8783</th>\n",
       "      <td>1/31/2022 18:02:15</td>\n",
       "      <td>44.734810</td>\n",
       "      <td>993.633484</td>\n",
       "      <td>79.296791</td>\n",
       "      <td>-8.110570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8784</th>\n",
       "      <td>1/31/2022 19:02:15</td>\n",
       "      <td>40.153286</td>\n",
       "      <td>993.961853</td>\n",
       "      <td>82.901161</td>\n",
       "      <td>-8.475571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8785 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Time     AI.csv     wsbp.csv   wsrh.csv   wsth.csv\n",
       "0     1/30/2021 19:02:15  37.000000  1005.968994  82.079987 -13.818200\n",
       "1     1/30/2021 20:02:15  33.223209  1006.039978  80.348824 -14.015130\n",
       "2     1/30/2021 21:02:15  36.000000  1006.090027  80.495888 -13.943720\n",
       "3     1/30/2021 22:02:15  34.903080  1006.140015  81.833351 -14.217760\n",
       "4     1/30/2021 23:02:15  34.484661  1006.190002  79.476692 -15.350870\n",
       "...                  ...        ...          ...        ...        ...\n",
       "8780  1/31/2022 15:02:15  43.375000   992.799988  86.986160  -7.212864\n",
       "8781  1/31/2022 16:02:15  41.029411   992.880371  79.485641  -7.497532\n",
       "8782  1/31/2022 17:02:15  41.365849   993.257019  78.728760  -7.782199\n",
       "8783  1/31/2022 18:02:15  44.734810   993.633484  79.296791  -8.110570\n",
       "8784  1/31/2022 19:02:15  40.153286   993.961853  82.901161  -8.475571\n",
       "\n",
       "[8785 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# читаем исходные данные для датасета и созадем датасет\n",
    "files = [\"AI.csv\", \"wsbp.csv\", \"wsrh.csv\", \"wsth.csv\"]\n",
    "i = 0\n",
    "\n",
    "for file in files:        \n",
    "    if i == 0:        \n",
    "        dset = pd.read_csv(file, names = [\"Time\", file], skiprows=[0])\n",
    "        i += 1\n",
    "    else:\n",
    "        dset = dset.merge(pd.read_csv(file, usecols = [\"Value\"]), left_index=True, right_index=True)        \n",
    "        dset.rename(columns = {\"Value\" : file}, inplace = True)\n",
    "# сохраним датасет\n",
    "dset.to_csv(\"original_dataset.csv\")\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Подготавлием данные для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8785 entries, 0 to 8784\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Time      8785 non-null   object \n",
      " 1   AI.csv    8664 non-null   float64\n",
      " 2   wsbp.csv  8667 non-null   float64\n",
      " 3   wsrh.csv  8665 non-null   float64\n",
      " 4   wsth.csv  8665 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 343.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# анализируем данные. видим пропуски\n",
    "dset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем время в формат времени из строк\n",
    "dset[\"Time\"] = pd.to_datetime(dset[\"Time\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполняем пропуски\n",
    "def fill_nan(data):    \n",
    "        mean = data.mean()\n",
    "#         print(data.name,data.mean())        \n",
    "        data.fillna(mean, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in files:\n",
    "    fill_nan(dset.loc[:,column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим распределение величин\n",
    "# fig, axs = plt.subplots(1, 5, figsize=(12, 7))\n",
    "for feature in dset.columns:\n",
    "    sns.displot(x=feature, data=dset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим доп колонку для месяца по времени\n",
    "dset[\"month\"] = 0\n",
    "dset[\"month\"] = dset[\"Time\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим доп колонку для дня\n",
    "dset[\"day\"] = 0\n",
    "dset[\"day\"] = dset[\"Time\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# конвертируем категориальные признаки в бинарные\n",
    "def convertdummies(X, columns):\n",
    "    dset_new = X.copy() # датасет с категориальными признаками\n",
    "    for column in columns:\n",
    "        dset_temp = pd.get_dummies(X[column], prefix=column)\n",
    "        dset_new = pd.merge(dset_new, dset_temp, left_index=True, right_index=True)\n",
    "        dset_new.drop(column, axis=1, inplace=True) # удаляем исходные \n",
    "    columns_new = dset_new.columns\n",
    "    return dset_new, columns_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# конвертируем категориальные признаки в бинарные\n",
    "columns_categorical = [\"month\", \"day\"]\n",
    "dset_new, columns_new = convertdummies(dset, columns_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Обучаем регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 чистые данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# задаем target\n",
    "y = dset.iloc[:,1]\n",
    "\n",
    "# задаем features\n",
    "X = dset.copy()\n",
    "X = X.drop([\"AI.csv\", \"Time\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "preds = lr.predict(X_test)\n",
    "result.append({\"R2_score\": r2_score(preds, y_test),\n",
    "               \"Type\": \"Чистая регрессия\"\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wsbp.csv</th>\n",
       "      <td>0.010959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsrh.csv</th>\n",
       "      <td>0.324206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wsth.csv</th>\n",
       "      <td>1.224347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coefficient\n",
       "wsbp.csv     0.010959\n",
       "wsrh.csv     0.324206\n",
       "wsth.csv     1.224347"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим веса признаков\n",
    "features = pd.DataFrame(lr.coef_[:3], \n",
    "                        files[1:], \n",
    "                        columns=['coefficient'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Скалированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стандартизуем входные данные\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scaled = LinearRegression()\n",
    "lr_scaled.fit(X_train_scaled, y_train)\n",
    "preds_scaled = lr_scaled.predict(X_test_scaled)\n",
    "result.append({\"R2_score\": r2_score(preds_scaled, y_test),\n",
    "               \"Type\": \"скалированная регрессия\"\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'R2_score': 0.7562792801797547, 'Type': 'Чистая регрессия'},\n",
       " {'R2_score': 0.7562792801797545, 'Type': 'скалированная регрессия'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему то результат одинаковый с не стандартизованными данными, хотя масштабы отличаются на порядок - два."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Добавляем дополнительные features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = dset_new.iloc[:,1]\n",
    "X_new = dset_new.copy()\n",
    "X_new = X_new.drop([\"AI.csv\", \"Time\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_new = LinearRegression()\n",
    "lr_new.fit(X_train_new, y_train_new)\n",
    "preds_new = lr_new.predict(X_test_new)\n",
    "result.append({\"R2_score\": r2_score(preds_new, y_test_new),\n",
    "               \"Type\": \"регрессия c доп фичами\"\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'R2_score': 0.7562792801797547, 'Type': 'Чистая регрессия'},\n",
       " {'R2_score': 0.7562792801797545, 'Type': 'скалированная регрессия'},\n",
       " {'R2_score': 0.8590059532520475, 'Type': 'регрессия c доп фичами'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат гораздо выше чем без категориального признака месяца"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обучаем бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем бустинг\n",
    "# обязательно удостовериться что версия библиотек одинаковая в conda и среде запуска серверной части иначе будет ошибка\n",
    "# %pip install --upgrade xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Без дополнительных features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBRegressor()\n",
    "xgboost.fit(X_train, y_train)\n",
    "xgb_predict = xgboost.predict(X_test)\n",
    "result.append({\"R2_score\": r2_score(xgb_predict, y_test),\n",
    "               \"Type\": \"бустинг без доп фич\"\n",
    "              })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 C дополнительными features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_new = xgb.XGBRegressor()\n",
    "xgboost_new.fit(X_train_new, y_train)\n",
    "xgb_predict_new = xgboost_new.predict(X_test_new)\n",
    "result.append({\"R2_score\": r2_score(xgb_predict_new, y_test),\n",
    "               \"Type\": \"бустинг c доп фичами\"\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'R2_score': 0.7562792801797547, 'Type': 'Чистая регрессия'},\n",
       " {'R2_score': 0.7562792801797545, 'Type': 'скалированная регрессия'},\n",
       " {'R2_score': 0.8590059532520475, 'Type': 'регрессия c доп фичами'},\n",
       " {'R2_score': 0.9378978480775644, 'Type': 'бустинг без доп фич'},\n",
       " {'R2_score': 0.9388382751165215, 'Type': 'бустинг c доп фичами'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним test\n",
    "X_test_new.to_csv(\"X_test.csv\", index=None)\n",
    "y_test.to_csv(\"y_test.csv\", index=None)\n",
    "# сохраним train\n",
    "X_train_new.to_csv(\"X_train.csv\", index=None)\n",
    "y_train.to_csv(\"y_train.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "# сохраняем модель\n",
    "with open(\"xgboost_model.dill\", \"wb\") as f:\n",
    "    dill.dump(xgboost_new, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>...</th>\n",
       "      <th>day_22</th>\n",
       "      <th>day_23</th>\n",
       "      <th>day_24</th>\n",
       "      <th>day_25</th>\n",
       "      <th>day_26</th>\n",
       "      <th>day_27</th>\n",
       "      <th>day_28</th>\n",
       "      <th>day_29</th>\n",
       "      <th>day_30</th>\n",
       "      <th>day_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month_1  month_2  month_3  month_4  month_5  month_6  month_7  month_8  \\\n",
       "0        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   month_9  month_10  ...  day_22  day_23  day_24  day_25  day_26  day_27  \\\n",
       "0        0         0  ...       0       0       0       0       0       0   \n",
       "\n",
       "   day_28  day_29  day_30  day_31  \n",
       "0       0       0       0       0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_month = [\"month_\" + str(i)  for i in range(1, 13)] # column names into Test dataset\n",
    "col_day = [\"day_\" + str(i) for i in range(1, 32)]  # column names into Test dataset\n",
    "df_months = pd.DataFrame(0, index=range(1), columns=col_month + col_day)\n",
    "df_months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг с доп фичами дал наилучший результат. Его и будем использовать"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
